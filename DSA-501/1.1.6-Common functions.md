# Common functions

**1.5 hours** Average completion time

#### What you'll learn

###### By the end of this lesson, you will be able to define several well-known functions used in the analysis of algorithms.

#### Overview

###### You have already seen two functions, f(n)=1 and f(n)=n. The running time of an algorithm may be expressed with any valid mathematical function. However, it is common practice to use one of several well-known functions. The functions commonly used in the analysis of algorithms are presented in this lesson in order from "best" to "worst."

## The constant function

The video below provides a brief introduction to constant functions.

The constant function is as follows:

f(n)=cf(n)=c

Here, c is some fixed constant. That is, for all values of n, the function f(n) remains equal to c. The most fundamental constant function is as follows:

f(n)=1f(n)=1

This is typically the function used to denote an algorithm with a constant order of growth.

For example, any basic operation, like adding two numbers together or assigning a value to a variable, is done in a single step. Therefore, it is constant.

Recall the summation of integers from 1 to n from the previous lesson:

`function sumIntegers2(n) {` `return (n * (n + 1)) / 2;`

`}`

You saw that this algorithm had an order of growth of O(1). You also saw this growth rate depicted on a graph like this:

![](https://images.ctfassets.net/c7lxnbtvvcxm/BIaLC5hC1vKffMHPZg3kB/671aa628778731d18e09de046f13944a/Eng-dsa_intro_014.png)

The meaning of O(1) is that the actual growth rate of this algorithm will be similar to the line f(n)=1 on the graph for all n.

## The logarithmic function

The video below provides a brief introduction to logarithmic functions.

Your friend says to you, "Let's play a game. I am thinking of a number between 1 and 10. What number am I thinking of?" How can you guess the number with the fewest possible guesses? Suppose you guess 1, and your friend says, "No, higher." Then you guess 8, and your friend says, "No, lower," and so on.

Random guessing will, of course, have a worst case of 10 guesses. But because your friend is telling you higher or lower after each guess, you can take advantage of that and split the problem in half.

For example, imagine that you guess 5. Now, if your friend says "higher," you only have the numbers 6-10 to work with. And if your friend says "lower," you only have the numbers 1-4 to work with.

Given this approach, what is the maximum number of guesses needed? Here is a decision tree that shows all the possible guesses:

![](https://images.ctfassets.net/c7lxnbtvvcxm/iIZINS3RgJHu6gox7NVOu/3792fc1a76a2c98f09b2b007eb56a4a8/Eng-dsa_intro_019.png)

With this approach, the worst possible case will take 4 guesses.

Now, your friend says, "I am thinking of a number between 1 and 20. What number am I thinking of?"

The problem is now twice as big. Once again, random guesses will result in a worst-case scenario of 20 guesses before getting the right answer. That is, it will take twice as long because the problem is twice as big.

But what is the worst case using the splitting technique? Is it twice as big as guessing from 10 numbers? Would it take you up to 8 guesses? Once again, you can use a decision tree to illustrate the guesses.

![](https://images.ctfassets.net/c7lxnbtvvcxm/1j40sSe37WFct4SPi4Zm0Y/957f046817e23da1611ca29cf9fa228b/Eng-dsa_intro_020.png)

The maximum number of guesses needed is only 5. The size of the problem was doubled, but the amount of work needed only increased by 1.

Similarly, if you double the problem to 40 numbers, the maximum number of guesses needed is only 6. And this goes on, no matter how big it gets. Try a few examples yourself to verify.

This growth rate, where the number of steps needed increases by 1 every time that the input size doubles, can be described by a logarithmic function. The logarithmic function is denoted as follows:

f(n)=log⁡nf(n)=logn

Graphically, it looks like this:

![](https://images.ctfassets.net/c7lxnbtvvcxm/7DC1eSE12HlMGwGrKWdD2G/5173b3fff0e83fbe79bcb0ae17c485f8/Eng-dsa_intro_021.png)

The red constant line was left in the diagram for comparison.

As you can see, the logarithmic curve continues to increase, but the curve gets flatter and flatter without ever being totally flat.

Algorithms like the guessing game above, which tend to split the problem in half at each iteration, generally have a logarithmic growth rate. In later modules, you will encounter several practical algorithms that have logarithmic growth rates.

## The linear function

The video below provides a brief introduction to linear functions.

The linear function is denoted as follows:

f(n)=nf(n)=n

This describes a growth rate that is proportional to the size of the input. That is, as the size of the data input to the problem increases, the number of steps correspondingly increases.

You have already encountered several algorithms with a growth rate of O(n). Generally, algorithms that involve a loop through each item in an array take linear time.

![](https://images.ctfassets.net/c7lxnbtvvcxm/IpUrSVux24sQAO2qHAsiV/bc5a1a3b7240fa4a2a596648f16e7f89/Eng-dsa_intro_022.png)

## The log-linear function

The log-linear function is denoted as follows:

f(n)=nlog⁡nf(n)=nlogn

This describes a growth rate that grows slightly faster than linear.

![](https://images.ctfassets.net/c7lxnbtvvcxm/6sUwwT0GAtuZqgAMcQfsld/15244d8086758693696057966e2f652c/Eng-dsa_intro_023.png)

Later in the program, you will encounter sorting algorithms with a growth rate of O(n log n).

## The quadratic function

The quadratic function is denoted as follows:

f(n)=n2f(n)=n2

This describes a growth rate that grows at the square of the size of the input. This growth rate is significantly faster than any of the other functions so far.

![](https://images.ctfassets.net/c7lxnbtvvcxm/g9396Kb0F51KGWTalHEzq/602b09ca2bf2f52de3c9eca6cfadf99c/Eng-dsa_intro_024.png)

Typically, algorithms with a nested loop will yield a growth rate of O(n²).

Here is an example: Suppose that you are given the prices for a particular stock each day for a number of days. You are allowed to make one purchase on any of the given days and then sell the stock on any subsequent day. Find the best day to buy and the best day to sell to maximize your profit.

The prices are in an array like this:

`const prices = [` `113,` `126,` `123,` `98,` `118,` `115,` `99,` `76,` `94,` `114,` `107,` `119,` `114,` `92,` `107,` `103,` `110,`

`];`

One option is to use a brute-force approach and compare the price on every day to every other day, like this:

`function maxSubArray(prices) {` `let bestBuy = -1;` `let bestSell = -1;` `let bestProfit = Number.NEGATIVE_INFINITY;` `for (let i = 0; i < prices.length - 1; i++) {` `for (let j = i + 1; j < prices.length; j++) {` `const profit = prices[j] - prices[i];` `if (profit > bestProfit) {` `bestBuy = i;` `bestSell = j;` `bestProfit = profit;` `}` `}` `}` `return [bestBuy, bestSell];`

`}`

To analyze the efficiency of this algorithm, you have to count the steps the same way as was done previously. The outer loop is straightforward to count.

![](https://images.ctfassets.net/c7lxnbtvvcxm/2tQX3bODSbxswRSnP3OFXb/ce60050ace5631b3a60c34675e6a24df/Eng-dsa_intro_025.png)

The inner loop, depicted in blue on the diagram, isn't so clear. On each iteration of the outer loop, the inner loop runs a different number of times. How can you determine the actual running time of those steps?

In the first iteration of the outer loop, the inner loop runs from 1 to n. That is, it runs n times. In the second iteration, it runs from 2 to n, or n-1 times. In the third, it runs from 3 to n, or n-2 times. If the array was of length 5, for example, the inner loop would run 5+4+3+2+1 times.

Luckily, you already saw that the sum of all integers from 1 to n is given by the formula n(n+1)/2. Therefore, you can say that each statement in the inner loop runs n(n+1)/2 times.

You can rearrange this to remove those parentheses as follows:

![](https://images.ctfassets.net/c7lxnbtvvcxm/50jOaqG3xjRfyaZZHhTmtw/164a9394b1941683d2c274ab6a4dc3d3/Eng-dsa_intro_026.png)

Don't be alarmed if the math here looks a bit complicated. In this program, you won't be required to do such math yourself. Just try to follow why the conclusions are drawn.

For the purposes of this analysis, you can then take it that each instruction in the inner loop takes this number of steps to complete. That gives you the following:

1+1+1+1+n+n−1+n−1+1+12n2+12n+12n2+12n+12n2+12n+12n2+12n+12n2+12n+12n2+12n+12n2+12n1+1+1+1+n+n−1+n−1+1+21​n2+21​n+21​n2+21​n+21​n2+21​n+21​n2+21​n+21​n2+21​n+21​n2+21​n+21​n2+21​n

So bring all the like terms together:

12n2+12n2+12n2+12n2+12n2+12n2+12n2+n+n+n+12n+12n+12n+12n+12n+12n+12n+1+1+1+1+1−1−121​n2+21​n2+21​n2+21​n2+21​n2+21​n2+21​n2+n+n+n+21​n+21​n+21​n+21​n+21​n+21​n+21​n+1+1+1+1+1−1−1

This can be simplified to the following:

72n2+102n+327​n2+210​n+3

But, you already saw that only the highest-order term really counts in this analysis. That means that you can drop the n term and the constant term, giving the following:

72n227​n2

And the constant coefficient doesn't matter, so you end up with this:

n2n2

Therefore, the order of growth of the running time of this algorithm is O(n²).

Even though the above analysis was done in painful detail, that isn't always necessary. This was done to illustrate that even though the inner loop was running a different number of times on each iteration of the outer loop, the running time of the algorithm was still O(n²).

For simple algorithms like this, you can look at the nested loop and assume that the running time is O(n²)—without going through all the steps.

## Cubic and higher-order polynomials

If a nested loop results in a running time of O(n²), what is the running time of triple nested loops? This running time can be defined by the cubic function:

f(n)=n3f(n)=n3

On the graph, this function grows faster than anything that you have seen so far.

![](https://images.ctfassets.net/c7lxnbtvvcxm/2lyJ9bqqi0TGPn46I61mnM/8bde54e5d0b8283ce68a5e77025e03b3/Eng-dsa_intro_027.png)

Consider the following problem:

A Pythagorean triplet is a set of three numbers {a, b, c} that satisfies the following equation:

a2+b2=c2a2+b2=c2

Find all Pythagorean triplets up to n.

To do this, you can once again use a brute-force technique that requires nested loops:

`function triplets(n) {` `const result = [];` `for (let a = 1; a <= n - 2; a++) {` `for (let b = a + 1; b <= n - 1; b++) {` `for (let c = b + 1; c <= n; c++) {` `if (a * a + b * b === c * c) {` `result.push([a, b, c]);` `}` `}` `}` `}` `return result;`

`}`

Without going through all the steps, it should be easy to spot that this algorithm has a growth rate of O(n³).

### Polynomials

A polynomial is a fancy mathematical term for a class of functions that involve multiple terms joined by addition, subtraction, multiplication, and integer exponents.

You have already seen several polynomial functions in this lesson.

For example, because n⁰=1, f(n)=1 is a polynomial expression. Also, because n¹=n, f(n)=n is also a polynomial.

Similarly, f(n)=n² and f(n)=n³ are polynomials.

It is rare that you will see algorithms with a running time as bad as O(n³), O(n⁴), or higher—but they do exist. This program will lump them all into the category of higher-order polynomials and consider them so bad that algorithms with such running times aren't practical.

## Exponential functions

Suppose you wish to write a program that will break a password by guessing every possible combination. For simplicity, suppose that you know that the password only consists of numbers. If the password is of length 2, how many combinations will you need to check?

`00` `01` `02` `03` `...` `10` `11` `12` `13` `...` `96` `97` `98`

`99`

That is 10², or 100 possible combinations. What if the password is of length 3? By similar logic, you can see that you need to try 10³, or 1,000 possible combinations.

In general, breaking a password of length n requires 10ⁿ tries. This gives the brute-force password-breaking algorithm a running time of O(10ⁿ).

Functions of the form shown below, where c is some constant, are called exponential functions.

f(n)=cnf(n)=cn

This running time is so bad that the exponential line looks almost parallel to the y-axis if it is plotted on a graph.

## Other functions

There are many other functions that may be used in the analysis of algorithms, but the ones covered here are the most commonly seen. In this module, you can assume that the running time of any algorithm provided falls into one of these categories.

## Summary

In summary, the functions discussed, in order of best to worst, are as follows:

|Name|Function|Use with big O|
|---|---|---|
|Constant|f(n) = 1|O(1)|
|Logarithmic|f(n) = log n|O(log n)|
|Linear|f(n) = n|O(n)|
|Log linear|f(n) = n log n|O(n log n)|
|Quadratic|f(n) = n²|O(n²)|
|Cubic|f(n) = n³|O(n³)|
|Higher-order polynomials|f(n) = nᵏ, where k > 3|O(nᵏ)|
|Exponential|f(n) = cⁿ, where c > 1 is a constant|O(cⁿ)|